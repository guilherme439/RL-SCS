import math
import os
from copy import deepcopy
from typing import Literal

import numpy as np
import torch
import yaml
from gymnasium import spaces
from pettingzoo import AECEnv
from termcolor import colored

from src.utils.package_utils import get_package_root
from src.render.SCS_Renderer import SCS_Renderer
from .Terrain import Terrain
from .Tile import Tile
from .Unit import Unit

r'''
From the hexagly source code: This is how the board is converted
from hexagonal to ortogonal representation:


 __    __                                 __ __ __ __
/11\__/31\__  . . .                      |11|21|31|41| . . .
\__/21\__/41\                            |__|__|__|__| 
/12\__/32\__/ . . .        _______|\     |12|22|32|42| . . .
\__/22\__/42\             |         \    |__|__|__|__| 
   \__/  \__/             |_______  /                           
 .  .  .  .  .                    |/       .  .  .  .  .
 .  .  .  .    .                           .  .  .  .    .
 .  .  .  .      .                         .  .  .  .      .


'''

r'''
This is how rows and collumns are defined for SCS Games.
This definition might be different from the examples in the hexagdly repository,
but I believe it makes more sense this way.


#   This is a row:
#    __    __                    __ __ __ __
#   /11\__/13\__     ----->     |11|12|13|14|       - Rows are horizontal
#   \__/12\__/14\               |__|__|__|__|
#      \__/  \__/
#

#   And this is a column:
#    __                          __
#   /11\                        |11|
#   \__/        ----->          |__|                - Columns are vertical
#   /21\                        |21|
#   \__/                        |__|
#

'''

class SCS_Game(AECEnv):

    PHASES = 2              # Check 'update_game_env()' 
    SUB_PHASES = 4
    STAGES = 10                

    N_PLAYERS = 2

    N_UNIT_STATUSES = 3     # Available, Moved, Attacked
    N_UNIT_STATS = 3        # Attack , Defense, Movement

    def __init__(
        self,
        game_config_path: str = "",
        seed: int | None = None,
        debug: bool = False,
        action_mask_location: Literal["info", "obs"] = "info",
        obs_space_format: Literal["channels_first", "channels_last", "flat"] = "channels_last",
    ):
        
        # ------------------------------------------------------------ #
        # --------------------- INITIALIZATION  ---------------------- #
        # ------------------------------------------------------------ #
        
        self.debug = debug
        self.action_mask_location = action_mask_location
        self.obs_space_format = obs_space_format
        self.package_root = get_package_root()

        self.title = "Default_Game"

        self.turns = 0
        self.stacking_limit = 0

        self.rows = 0
        self.columns = 0
        self.board = []

        self.update_player(0)
        self.current_phase = 0
        self.current_sub_phase = 0
        self.current_stage = -2   
        self.current_turn = 0


        self.available_units = [[],[]]      # Units that have not moved yet
        self.moved_units = [[],[]]          # Units that moved but didn't attack
        self.attacked_units = [[],[]]       # Units that already attacked

        self.target_tile = None
        self.attackers = []

        self.victory_points = [[],[]] 
        self.n_vp = [0, 0]

        self.all_reinforcements = {0:[], 1:[]}
        self.current_reinforcements = {0:[], 1:[]}

        self.p1_last_index = 0
        self.p2_first_index = 0

        self.length = 0
        self.terminal_value = 0
        self.terminal = False


        self.renderer = SCS_Renderer()

        # ------------------------------------------------------ #
        # --------------- MCTS RELATED ATRIBUTES --------------- #
        # ------------------------------------------------------ #

        self.child_policy = []
        self.state_history = []
        self.player_history = []
        self.action_history = []

        # ------------------------------------------------------ #
        # --------------- GAME ENVIORNMENT --------------- #
        # ------------------------------------------------------ #

        # If a config is not provided we can not initialize any further
        if game_config_path == "":
            return

        self.load_game_from_config(game_config_path, seed)

    
        # ------------------------------------------------------- #
        # ---------- STATE AND ACTION REPRESENTATIONS ----------- #
        # ------------------------------------------------------- #

        ## ACTION REPRESENTATION

        # Reinforcements
        self.placement_planes = 1
        # Movement
        self.movement_planes = 6 * self.stacking_limit
        # Fighting
        self.choose_target_planes = 1
        self.choose_attackers_planes = self.stacking_limit
        self.confirm_attack_planes = 1
        self.fight_planes = self.choose_target_planes + self.choose_attackers_planes + self.confirm_attack_planes
        # Other
        self.no_move_planes = self.stacking_limit
        self.no_fight_planes = self.stacking_limit

        self.total_action_planes = \
        self.placement_planes + \
        self.movement_planes + \
        self.fight_planes + \
        self.no_move_planes + \
        self.no_fight_planes
        
        self.action_space_shape = (self.total_action_planes , self.rows , self.columns)
        self.num_actions     =     self.total_action_planes * self.rows * self.columns

        # Plane borders
        self.placement_limit = self.placement_planes
        self.movement_limit = self.placement_limit + self.movement_planes
        self.target_limit = self.movement_limit + self.choose_target_planes
        self.attackers_limit = self.target_limit + self.choose_attackers_planes
        self.confirm_limit = self.attackers_limit + self.confirm_attack_planes
        self.no_move_limit = self.confirm_limit + self.no_move_planes
        self.no_fight_limit = self.no_move_limit + self.no_fight_planes
        # Each of these limits represents the first index of the next section

        # Action space: Discrete (flattened from 3D structure)
        # Actions are integers 0 to num_actions-1, internally converted to (plane, row, col)
        # This is the only space type that supports action masking in PettingZoo
        self._action_space = spaces.Discrete(self.total_action_planes * self.rows * self.columns)


        ## STATE REPRESENTATION
        
        # TERRAIN
        self.n_terrain_channels = 3 # atack, defense, movement
        # Each position can contain any positive R value representing terrain modifiers

        # VICTORY POINTS
        self.n_vp_channels = self.N_PLAYERS
        # Binary planes where victory point locations are marked with a 1

        # UNITS
        self.n_unit_representation_channels = self.N_UNIT_STATS * self.stacking_limit * self.N_UNIT_STATUSES * self.N_PLAYERS
        # Each position can contain any positive integer value, representing units stats


        # REINFORCEMENTS
        self.n_reinforcements = 3  # Number of reinforcements that are represented per player
        self.n_reinforcement_channels = self.n_reinforcements * self.N_UNIT_STATS
        # For each unit there will be 2 sets of planes:
        # the first representing the unit itself and
        # the second representing how many turns until that unit arrives
        self.n_duration_channels = self.n_reinforcement_channels
        self.n_total_reinforcement_channels = (self.n_reinforcement_channels + self.n_duration_channels) * self.N_PLAYERS
        # For the reinforcement_channels each position can contain any positive integer value, representing units stats
        # For the duration_channels each position can contain any integer value between 0 and self.turns

        # ATTACK
        self.n_target_tile_channels = 1
        self.n_attacker_channels = self.stacking_limit
        self.n_attack_channels = self.n_target_tile_channels + self.n_attacker_channels
        # These are binary planes marking the tiles being attacked and the positions of each attacker


        # FEATURES
        self.n_sub_phase_channels = self.SUB_PHASES
        # Activation channels that get entierly filled with 1's during the respective sub_phase, and filled with 0's otherwise

        self.n_turn_channels = 1
        # a plane filled with a value between 0 and 1, representing the current turn

        self.n_player_channels = 1
        # a plane filled with either 1's our -1's representing the current player

        self.n_feature_channels = self.n_sub_phase_channels + self.n_turn_channels + self.n_player_channels

        self.total_dims = \
        self.n_vp_channels + \
        self.n_unit_representation_channels + \
        self.n_total_reinforcement_channels + \
        self.n_feature_channels + \
        self.n_terrain_channels + \
        self.n_attack_channels

        # State shape depends on obs_space_format:
        # - channels_first: (C, H, W) - PyTorch convention
        # - channels_last: (H, W, C) - TensorFlow/RLlib convention
        # - flat: (C * H * W,) - 1D flattened, works with FC networks
        if self.obs_space_format == "channels_first":
            self.game_state_shape = (self.total_dims, self.rows, self.columns)
        elif self.obs_space_format == "channels_last":
            self.game_state_shape = (self.rows, self.columns, self.total_dims)
        else:  # flat
            self.game_state_shape = (self.total_dims * self.rows * self.columns,)

        self._state_space = spaces.Box(
            low=-1,                           # Minimum value (-1 for player channels)
            high=np.inf,                      # Maximum value (infinity for unit stats and terrain)
            shape=self.game_state_shape,
            dtype=np.float32                  # Using float32 to handle continuous values
        )
        
        # Observation space depends on action_mask_location:
        # - "info": observation is just the state Box (action mask in info dict)
        # - "obs": observation is a Dict with state and action mask
        if self.action_mask_location == "obs":
            self._observation_space = spaces.Dict({
                "observation": self._state_space,
                "action_mask": spaces.MultiBinary(self.num_actions)
            })
        else:  # "info"
            self._observation_space = self._state_space


        
        ## PettingZoo

        self.agents = [self.get_agent_name(p) for p in range(self.N_PLAYERS)]
        self.possible_agents = [self.get_agent_name(p) for p in range(self.N_PLAYERS)]

        self.rewards = {}
        self._cumulative_rewards = {}
        self.infos = {}
        self.truncations = {}
        self.terminations = {}

        # The action and observation spaces are the same for both players
        # Action masking is used to determine invalid actions at any moment
        self.observation_spaces = {}
        self.action_spaces = {}
        for agent in self.agents:
            self.observation_spaces[agent] = self._observation_space
            self.action_spaces[agent] = self._action_space
            self.rewards[agent] = 0
            self._cumulative_rewards[agent] = 0
            self.infos[agent] = {"action_mask": None}
            self.truncations[agent] = False
            self.terminations[agent] = False

        # Simulation mode simplifies the game
        # to only use absolutelly necessary properties
        # in order to speed up games,
        # when running thousands of simulations
        self.simulation_mode = False


        # ------------------ #
        self.update_game_env()

        return
    
##########################################################################
# -------------------------                    ------------------------- #
# -----------------------  GET AND SET METHODS  ------------------------ #
# -------------------------                    ------------------------- #
##########################################################################

    def get_dirname(self):
        return "SCS"
    
    def get_title(self):
        return self.title

    def get_board(self):
        return self.board
    
    def getBoardColumns(self):
        return self.columns

    def getBoardRows(self):
        return self.rows    

    def get_agent_name(self, player: int) -> str:
        """Convert player index to agent name for PettingZoo API"""
        return f"player_{player}"
    
    def update_player(self, player: int) -> None:
        """Update current player and sync agent_selection"""
        self.current_player = player
        self.agent_selection = self.get_agent_name(player)

    def get_current_player(self):
        return self.current_player
    
    def get_terminal_value(self):
        return self.terminal_value

    def get_length(self):
        return self.length

    def get_action_space_shape(self):
        return self.action_space_shape

    def get_num_actions(self):
        return self.num_actions

    def get_state_shape(self):
        return self.game_state_shape

    def get_state_from_history(self, i):
        return self.state_history[i]

    def get_tile(self, position):
        return self.board[position[0]][position[1]]

    def observation_space(self, agent):
        '''
        Because the game currently is fully observable
        the observation space will return the same for both agents
        '''
        return self.observation_spaces[agent]

    def action_space(self, agent):
        '''
        Currently this function returns
        the entire action space for both agents
        '''
        return self.action_spaces[agent]

    def store_state(self, state):
        self.state_history.append(state)
        return

    def store_player(self, player):
        self.player_history.append(player)
        return
    
    def store_action(self, action_coords):
        self.action_history.append(action_coords)

    def get_player_index(self, player_string: str) -> int:
        prefix_len = 7 # "player_" has 7 letters
        return int(player_string[prefix_len:])


##########################################################################
# ----------------------------              ---------------------------- #
# ---------------------------   GAME LOGIC   --------------------------- #
# ----------------------------              ---------------------------- #
##########################################################################

    def step(self, action: np.integer | None) -> None:
        """
        Execute an action in the environment.
        
        Args:
            action: Integer from 0 to num_actions-1 from the Discrete action space,
                   representing a flattened 3D coordinate (plane, row, col),
                   or None if the agent is terminated/truncated (PettingZoo convention)
        
        If an invalid action is played (for some reason), the offending player immediately loses. 
        """
        if self.debug:
            print(f"[DEBUG] step() called: action={action}, agent={self.agent_selection}, terminal={self.terminal}")
        
        agent = self.agent_selection
        
        if self.terminations.get(agent, False) or self.truncations.get(agent, False):
            self._was_dead_step(action)
            return
        
        self._cumulative_rewards[agent] = 0
        
        if action is not None:
            is_valid: bool = True
            if not self.simulation_mode:
                action_mask: np.ndarray = self.possible_actions().flatten()
                is_valid = bool(action_mask[action])
                if not is_valid:
                    if self.debug:
                        print(f"[DEBUG] Invalid action {action} by player {self.current_player}")
                    self.terminate_invalid_action(self.current_player)
            
            if is_valid:
                action_coords: tuple[int, int, int] = self.get_action_coords(action)
                self.store_action(action_coords)
                self.play_action(action_coords) 
                self.length += 1
        
        self.update_game_env()
        
        if self.debug:
            print(f"[DEBUG] step() done: terminal={self.terminal}, agent={self.agent_selection}")
        return

    # ----------------- ACTIONS ----------------- #

    def possible_actions(self):
        player = self.current_player
        
        # PLANE DEFINITIONS
        placement_planes = np.zeros((self.placement_planes, self.rows, self.columns), dtype=np.int8)

        movement_planes = np.zeros((self.movement_planes, self.rows, self.columns), dtype=np.int8)

        choose_target_planes = np.zeros((self.choose_target_planes, self.rows, self.columns), dtype=np.int8)
        choose_attackers_planes = np.zeros((self.choose_attackers_planes, self.rows, self.columns), dtype=np.int8)
        confirm_attack_planes = np.zeros((self.confirm_attack_planes, self.rows, self.columns), dtype=np.int8)

        no_move_planes = np.zeros((self.no_move_planes, self.rows, self.columns), dtype=np.int8)
        no_fight_planes = np.zeros((self.no_fight_planes, self.rows, self.columns), dtype=np.int8)
        
        # PLACING REINFORCEMENTS
        if self.current_sub_phase == 0:
            # In this sub_phase the player places his reinforcements

            next_reinforcement = self.get_next_reinforcement()
            arraival_locations = next_reinforcement.get_arraival_locations()
            for (row, col) in arraival_locations:
                tile: Tile = self.board[row][col]
                # can not place on tiles controlled by the other player or that are already full.
                if not ( (tile.player == self.opponent(player)) or (tile.stacking_number() == self.stacking_limit) ):
                    placement_planes[0][row][col] = 1       
        
        # MOVING
        elif self.current_sub_phase == 1:
            # In this sub_phase the player can either choose a unit to move or end it's movement

            for unit in self.available_units[player]:
                (x, y) = unit.position
                tile = self.board[x][y]

                s = tile.get_stacking_level(unit)
                no_move_planes[s][x][y] = 1 # no move action

                tiles = self.check_tiles((x,y))
                movements = self.check_mobility(unit, consider_other_units=True)

                for i in range(len(tiles)):
                    tile = tiles[i]
                    if (tile):
                        if(movements[i]):
                            plane_index = i * self.stacking_limit + s
                            movement_planes[plane_index][x][y] = 1

        # ATTACKING
        elif self.current_sub_phase == 2:
            # In this sub_phase the player can either choose a target or select a unit as done attacking
            
            for unit in self.moved_units[player]:
                (x, y) = unit.position
                tile = self.board[x][y]

                s = tile.get_stacking_level(unit)
                no_fight_planes[s][x][y] = 1 # no fight action

                enemy_player = self.opponent(player)
                enemy_units = self.check_adjacent_units(unit.position, enemy_player)
                for enemy_unit in enemy_units:
                    (row, col) = enemy_unit.position
                    choose_target_planes[0][row][col] = 1 # select target action

        elif self.current_sub_phase == 3:
            # In this sub_phase the player can either select a unit to attack with or confirm the attack

            selectable_units = self.check_adjacent_units(self.target_tile.position, player)
            for unit in selectable_units.copy():
                if (unit in self.attackers) or (unit in self.attacked_units[player]):
                    selectable_units.remove(unit)

            for unit in selectable_units:
                (x, y) = unit.position
                tile = self.board[x][y]
                s = tile.get_stacking_level(unit)
                choose_attackers_planes[s][x][y] = 1 # choose attacker action

            num_attackers = len(self.attackers)
            if num_attackers > 0:
                (x,y) = self.target_tile.position
                confirm_attack_planes[0][x][y] = 1 # confirm attack action
        
        else:
            raise Exception("Error in possible_actions! Exiting")

        planes_list = [placement_planes, movement_planes, choose_target_planes, choose_attackers_planes, confirm_attack_planes, no_move_planes, no_fight_planes]
        valid_actions_mask = np.concatenate(planes_list)
        return valid_actions_mask
                      
    def parse_action(self, action_coords):
        act = None           # Represents the type of action
        start = (None, None) # Starting point of the action
        stacking_lvl = None  # Stacking level
        dest = (None, None)  # Destination point for the action

        current_plane = action_coords[0]


        # PLACEMENT PLANES
        if current_plane < self.placement_limit:
            act = 0
            start = (action_coords[1], action_coords[2])

        # MOVEMENT PLANES
        elif current_plane < self.movement_limit:
            act = 1
            x = action_coords[1]
            y = action_coords[2]
            start = (x, y)

            plane_index = current_plane - self.placement_limit
            stacking_lvl = plane_index % self.stacking_limit
            direction = plane_index // self.stacking_limit

            # n, ne, se, s, sw, nw
            if direction == 0:    # N
                dest = self.get_n_coords(start)

            elif direction == 1:  # NE
                dest = self.get_ne_coords(start)

            elif direction == 2:  # SE
                dest = self.get_se_coords(start)

            elif direction == 3:  # S
                dest = self.get_s_coords(start)

            elif direction == 4:  # SW
                dest = self.get_sw_coords(start)

            elif direction == 5:  # NW
                dest = self.get_nw_coords(start)
            else:
                raise Exception("Problem parsing action...Exiting")
            
        # FIGHT PLANES
        elif current_plane < self.target_limit:
            act = 2
            x = action_coords[1]
            y = action_coords[2]
            start = (x, y)

        elif current_plane < self.attackers_limit:
            act = 3
            start = (action_coords[1], action_coords[2])

            plane_index = current_plane - self.target_limit
            stacking_lvl = plane_index

        elif current_plane < self.confirm_limit:
            act = 4
            start = (action_coords[1],action_coords[2])

        # NO_MOVE PLANE
        elif current_plane < self.no_move_limit:
            act = 5
            plane_index = current_plane - self.confirm_limit
            stacking_lvl = plane_index
            start = (action_coords[1],action_coords[2])

        # NO_FIGHT PLANE
        elif current_plane < self.no_fight_limit:
            act = 6
            plane_index = current_plane - self.no_move_limit
            stacking_lvl = plane_index
            start = (action_coords[1],action_coords[2])

        else:
            raise Exception("Problem parsing action...Exiting")

        return (act, start, stacking_lvl, dest)

    def play_action(self, action_coords):
        if self.terminal:
            return
        
        (act, start, stacking_lvl, dest) = self.parse_action(action_coords)

        if (act == 0): # Placement
            player = self.current_player
            turn = self.current_turn
            new_unit = self.current_reinforcements[player][turn].pop(0)
            new_unit.move_to(start, 0)
            self.available_units[player].append(new_unit)

            tile = self.get_tile(start)
            tile.place_unit(new_unit)

        elif (act == 1): # Movement
            start_tile = self.board[start[0]][start[1]]
            unit = start_tile.get_unit_by_level(stacking_lvl)

            if start != dest:
                dest_tile = self.get_tile(dest)
                
                terrain = dest_tile.get_terrain()
                cost = terrain.cost

                unit.move_to(dest, cost)
                dest_tile.place_unit(unit)
                start_tile.remove_unit(unit)

                # Ends the movement of units who don't have enough movement points
                # to reduce total number of decisions that need to be taken per game
                if not any(self.check_mobility(unit, consider_other_units=False)): 
                    self.end_movement(unit)
                # This verification is done here to avoid checking all the units, or keeping an 'updated_units_list'
           
            else:
                raise Exception("Problem playing action.\n \
                      Probably there is a bug in possible_actions().")

        elif (act == 2): # Choosing target
            target_tile = self.get_tile(start)
            self.target_tile = target_tile
        
        elif (act == 3): # Choosing attacker
            tile = self.get_tile(start)
            unit = tile.get_unit_by_level(stacking_lvl)
            self.attackers.append(unit)

        elif (act == 4): # Confirming attack
            self.resolve_combat()
            self.target_tile = None # clear target tile
            self.attackers.clear()  # reset attackers

        elif (act == 5): # No movement
            tile = self.get_tile(start)
            unit = tile.get_unit_by_level(stacking_lvl)
            self.end_movement(unit)

        elif (act == 6): # No fighting
            tile = self.board[start[0]][start[1]]
            unit = tile.get_unit_by_level(stacking_lvl)
            self.end_fighting(unit)

        else:
            raise Exception("Play_action: Unknown action.")

        return

    # --------------- ENVIRONMENT --------------- #


    def reset(self, seed=None, options=None):
        if self.debug:
            print(f"[DEBUG] reset() called")

        self.update_player(0)
        self.current_phase = 0   
        self.current_sub_phase = 0
        self.current_stage = -2 
        self.current_turn = 0

        self.target_tile = None
        self.attackers = []

        self.length = 0
        self.terminal_value = 0
        self.terminal = False

        for p in range(self.N_PLAYERS):
            self.available_units[p].clear()
            self.moved_units[p].clear()
            self.attacked_units[p].clear()
            
        self.agents = self.possible_agents.copy()
        for agent in self.agents:
            self.rewards[agent] = 0
            self._cumulative_rewards[agent] = 0
            self.truncations[agent] = False
            self.terminations[agent] = False
            self.infos[agent] = {"action_mask": None}


        self.current_reinforcements = deepcopy(self.all_reinforcements)
        
        for i in range(self.rows):
            for j in range(self.columns):
                self.board[i][j].reset() # reset each tile    

        
        # MCTS RELATED ATRIBUTES 
        self.child_policy.clear()
        self.state_history.clear()
        self.player_history.clear()
        self.action_history.clear()

        self.update_game_env()

        action_mask = self.possible_actions().flatten()
        for agent in self.agents:
            self.infos[agent]["action_mask"] = action_mask

        if self.debug:
            print(f"[DEBUG] reset() done: agents={self.agents}, rewards_keys={list(self.rewards.keys())}")

        return None

    def update_game_env(self):
        if not self.terminal:
            self.update_env_stages()
            self.update_env_player()

            if not self.simulation_mode:
                possible = self.possible_actions().flatten()
                for agent in self.agents:
                    self.infos[agent]["action_mask"] = possible

        self._accumulate_rewards()
        return

    def update_env_stages(self):
        # Two players: P1 and P2
        # Each player's turn has two phases: Movement, Fighting
        # Each phase has 2 sub-phases:
        # Movement sub-phases -> reinforcement | movement
        # Fighting sub-phases -> choosing target | choosing attackers
        # This results in 4 total sub-phases for each player.

        # Turn 0 happens before game start, and is where both player place their initial troops.
        # Turn 0 only has 1 sub-phase for each player (reinforcement)

        # I call "stage" to each unique sub-phase of the game.
        # There are a total of 10 stages:
        # 2 stages in turn 0 (1 for each player's reinforcement sub-phase)
        # 8 stages in other turns (4 for each player)

        done = False
        previous_player = self.agent_selection
        previous_stage = self.current_stage
        stage = previous_stage

        # Turn 0 stages are represented with -2 and -1
        while True:
            match stage:
                case -2:
                    if self.current_turn != 0:
                        raise Exception("Sanity check went wrong. Something wrong with game environment.")
                    
                    if self.player_ended_reinforcements(0, self.current_turn):
                        stage+=1
                        continue

                case -1:
                    if self.current_turn != 0:
                        raise Exception("Sanity check went wrong. Something wrong with game environment.")
                    
                    if self.player_ended_reinforcements(1, self.current_turn):
                        self.current_turn+=1
                        stage+=1
                        continue
                
                case 0: # P1 reinforcements
                    if self.player_ended_reinforcements(0, self.current_turn):
                        stage+=1
                        continue
                
                case 1: # P1 movement
                    if self.player_ended_movement(0):
                        stage+=1
                        continue
                    
                case 2: # P1 choosing target
                    if self.player_done_attacking(0):
                        stage = 4
                        continue
                        
                    elif self.player_chose_target(0):
                        stage+=1
                        continue

                case 3: # P1 selecting attackers
                    if self.player_confirmed_attack(0):
                        stage = 2
                        continue
                    
                case 4: # P2 reinforcements
                    if self.player_ended_reinforcements(1, self.current_turn):
                        stage+=1
                        continue
                    
                case 5: # P2 movement
                    if self.player_ended_movement(1):
                        stage+=1
                        continue                                                      

                case 6: # P2 choosing target
                    if self.player_done_attacking(1):
                        if self.current_turn+1 > self.turns:
                            done = True
                            break
                        self.current_turn+=1
                        stage = 0
                        self.new_turn()
                        continue
            
                    elif self.player_chose_target(1):
                        stage+=1
                        continue         
                    
                case 7: # P2 selecting attackers
                    if self.player_confirmed_attack(1):
                        stage = 6
                        continue
            break

        # ------------------------------------    

        reinforcement_stages = self.reinforcement_stages()
        movement_stages = self.movement_stages()
        choosing_target_stages = self.choosing_target_stages()
        choosing_attackers_stages = self.choosing_attackers_stages()

        if stage in reinforcement_stages:
            self.current_sub_phase = 0
        elif stage in movement_stages:
            self.current_sub_phase = 1
        elif stage in choosing_target_stages:
            self.current_sub_phase = 2
        elif stage in choosing_attackers_stages:
            self.current_sub_phase = 3
        else:
            raise Exception("Error in function: \'update_game_env()\'.")

        if self.current_sub_phase in (0,1):
            self.current_phase = 0
        elif self.current_sub_phase in (2,3):
            self.current_phase = 1
        else:
            raise Exception("Error in function: \'update_game_env()\'.")

        self.current_stage = stage

        if(done):
            self.terminal = True
            self.evaluate_termination()

        return
    
    def update_env_player(self):
        p1_stages = (-2,0,1,2,3)
        p2_stages = (-1,4,5,6,7)
        if self.current_stage in p1_stages:
            self.update_player(0)
        elif self.current_stage in p2_stages:
            self.update_player(1)
        else:
            raise Exception("Error in function: \'update_game_env()\'.")
        return

    def reinforcement_stages(self):
        return (-2,-1,0,4)
    
    def movement_stages(self):
        return (1,5)
    
    def choosing_target_stages(self):
        return (2,6)
    
    def choosing_attackers_stages(self):
        return (3,7)

    def new_turn(self):
        # Resets units status before new turn
        self.available_units = self.attacked_units.copy()
        self.attacked_units = [[], []]

        for p in [0,1]:
            for unit in self.available_units[p]:
                unit.reset_mov()
                unit.set_status(0)

        return  

    def terminate_invalid_action(self, offending_player: int) -> None:
        if self.debug:
            print(f"[DEBUG] terminate_invalid_action() called: offending_player={offending_player}")
        
        self.terminal = True
        self._evaluate_invalid_action_termination(offending_player)
        
        if self.debug:
            print(f"[DEBUG] terminate_invalid_action() done: terminal_value={self.terminal_value}")

    def _evaluate_invalid_action_termination(self, offending_player: int) -> None:
        ''' 
            Update terminal values and rewards for when a player makes an invalid action.
            The offending player immediately loses the game.
        '''
        if offending_player == 0:
            self.terminal_value = -1  # Player 1 wins
            p1_reward: int = -1
            p2_reward: int = 1
        else:
            self.terminal_value = 1   # Player 0 wins
            p1_reward = 1
            p2_reward = -1
        
        self.rewards[self.get_agent_name(0)] = p1_reward
        self.rewards[self.get_agent_name(1)] = p2_reward
        
        self.terminations[self.get_agent_name(0)] = True
        self.terminations[self.get_agent_name(1)] = True

    def evaluate_termination(self) -> None:
        if self.debug:
            print(f"[DEBUG] evaluate_termination() called: agents={self.agents}, rewards_keys={list(self.rewards.keys())}")
        
        p1_captured_points = 0
        p2_captured_points = 0
        victory_p1 = self.victory_points[0]
        victory_p2 = self.victory_points[1]
        for point in victory_p1:
            vic_p1 = self.board[point[0]][point[1]]
            if vic_p1.player == 1:
                p2_captured_points +=1
        for point in victory_p2:
            vic_p2 = self.board[point[0]][point[1]]
            if vic_p2.player == 0:
                p1_captured_points +=1

        p1_percentage_captured = p1_captured_points / self.n_vp[1]
        p2_percentage_captured = p2_captured_points / self.n_vp[0]

        if p1_percentage_captured > p2_percentage_captured:
            final_value = 1     # p1 victory
            p1_reward = 1
            p2_reward = -1
        elif p1_percentage_captured < p2_percentage_captured:
            final_value = -1    # p2 victory
            p1_reward = -1
            p2_reward = 1
        else:
            final_value = 0     # draw
            p1_reward = 0
            p2_reward = 0
        
        self.terminal_value = final_value
        self.rewards[self.get_agent_name(0)] = p1_reward
        self.rewards[self.get_agent_name(1)] = p2_reward
        
        self.terminations[self.get_agent_name(0)] = True
        self.terminations[self.get_agent_name(1)] = True
        
        if self.debug:
            print(f"[DEBUG] evaluate_termination() done: terminal={self.terminal}, terminations={self.terminations}")

    def get_winner(self):
        terminal_value = self.get_terminal_value()

        if terminal_value < 0:
            winner = 2
        elif terminal_value > 0:
            winner = 1
        else:
            winner = 0

        return winner

    def player_ended_reinforcements(self, player, turn):
        player_index = player
        turn_index = turn
        return self.current_reinforcements[player_index][turn_index] == []
    
    def player_ended_movement(self, player):
        player_index = player
        return self.available_units[player_index] == []
        
    def player_done_attacking(self, player):
        player_index = player
        return self.moved_units[player_index] == []        

    def player_chose_target(self, player):
        return (self.target_tile is not None)
    
    def player_confirmed_attack(self, player):
        return (self.target_tile is None)      

    def end_movement(self, unit: Unit):
        # End movement
        unit.set_status(1)
        player_idx = unit.player
        self.moved_units[player_idx].append(unit)
        self.available_units[player_idx].remove(unit)

        # Since enemies can not move during my turn we can
        # mark isolated units as done fighting to reduce
        # the total number of decisions that need to be taken
        enemy = self.opponent(unit.player)
        enemy_units = self.check_adjacent_units(unit.position, enemy)
        if len(enemy_units) == 0:
            self.end_fighting(unit)

    def end_fighting(self, unit: Unit):
        unit.set_status(2)
        player_idx = unit.player
        self.attacked_units[player_idx].append(unit)
        self.moved_units[player_idx].remove(unit)
        
    # ------------------ COMBAT ------------------ #
    
    def destroy_unit(self, unit):
        (x, y) = unit.position
        self.board[x][y].remove_unit(unit)
        player_index = unit.player
        
        # Global reference list to each status caused problems, so I use a local list instead
        all_statuses = [self.available_units, self.moved_units, self.attacked_units]

        try:
            all_statuses[unit.status][player_index].remove(unit)
        except ValueError:
            raise Exception("Could not destroy unit.\nPossible error tracking the unit's status.")

        return

    def resolve_combat(self):
        attacking_player = self.current_player
        defending_player = self.opponent(attacking_player)
        
        # DEFENSE
        target_tile = self.target_tile
        defense_modifier = target_tile.get_terrain().defense_modifier
        total_defense = 0
        defending_units = target_tile.units
        for unit in defending_units:
            total_defense += unit.defense
        total_defense = total_defense * defense_modifier

        # ATTACK
        total_attack = 0
        for unit in self.attackers:
            unit_tile = self.board[unit.position[0]][unit.position[1]]
            attack_modifier = unit_tile.get_terrain().attack_modifier
            total_attack += unit.attack * attack_modifier
            self.end_fighting(unit)

        # RESULTS
        attacker_losses, defender_losses = self.get_combat_results(total_attack, total_defense)

        for loss in range(attacker_losses):
            unit = self.get_strongest_attacker(self.attackers)
            self.destroy_unit(unit)

        for loss in range(defender_losses):
            unit = self.get_strongest_defender(defending_units)
            self.destroy_unit(unit)

    def get_combat_results(self, total_attack, total_defense):
        # In the future this function should use a combat table
        attacker_losses = 0
        defender_losses = 0

        if total_attack > total_defense:    # defender loses a unit
            defender_losses = 1

        elif total_attack < total_defense:  # attacker loses a unit
            attacker_losses = 1
        
        else:                               # both lose a unit
            attacker_losses = 1
            defender_losses = 1

        return attacker_losses, defender_losses

    # ------------------ OTHER ------------------ #

    def check_tiles(self, coords):
        ''' Clock-wise rotation order '''

        r'''
             n
        nw   __   ne
            /  \ 
            \__/ 
        sw        se
              s
        '''
        (row, col) = coords

        n = None
        ne = None
        se = None
        s = None
        sw = None
        nw = None


        if (row-1) != -1:
            (x, y) = self.get_n_coords(coords)
            n = self.board[x][y]

        if (row+1) != self.rows:
            (x, y) = self.get_s_coords(coords)
            s = self.board[x][y]

        if not ((col == 0) or (row == 0 and col % 2 == 0)):
            (x, y) = self.get_nw_coords(coords)
            nw = self.board[x][y]

        if not ((col == 0) or (row == self.rows-1 and col % 2 != 0)):
            (x, y) = self.get_sw_coords(coords)
            sw = self.board[x][y]

        if not ((col == self.columns-1) or (row == 0 and col % 2 == 0)):
            (x, y) = self.get_ne_coords(coords)
            ne = self.board[x][y]

        if not ((col == self.columns-1) or (row == self.rows-1 and col % 2 != 0)):
            (x, y) = self.get_se_coords(coords)
            se = self.board[x][y]
        

        return n, ne, se, s, sw, nw

    def check_mobility(self, unit, consider_other_units=False):  

        tiles = self.check_tiles(unit.position)
        can_move = [False for i in range(len(tiles))]

        for i in range(len(tiles)):
            tile = tiles[i]
            if tile:
                cost = tile.get_terrain().cost
                dif = unit.mov_points - cost
                if dif >= 0:
                    can_move[i] = True
                    if consider_other_units and ((tile.stacking_number() == self.stacking_limit) or (tile.player == self.opponent(unit.player))):
                        can_move[i] = False

        return can_move
    
    def check_adjacent_units(self, position, player):

        tiles = self.check_tiles(position)
        adjacent_units = []
        for i in range(len(tiles)):
            tile = tiles[i]
            if tile:
                for unit in tile.units:
                    if (unit.player==player):
                        adjacent_units.append(unit)

        return adjacent_units

    
##########################################################################
# -------------------------                   -------------------------- #
# ------------------------   UTILITY METHODS   ------------------------- #
# -------------------------                   -------------------------- #
##########################################################################

    def is_terminal(self):
        return self.terminal

    def opponent(self, player):
        # just flips the bit
        return player ^ 1

    def define_board_sides(self):
        '''Calculates the indexes for each of the board's sides'''

        # Calculate the indexes that define each side of the board
        if self.columns % 2 != 0:
            middle_index = math.floor(self.columns/2)
            self.p1_last_index = middle_index-1
            self.p2_first_index = middle_index+1
        else:
            # if number of columns is even there are two middle columns: one on the right and one on the left
            mid = int(self.columns/2)
            left_side_collumn = mid
            right_side_collumn = mid + 1
            left_index = left_side_collumn - 1
            right_index = right_side_collumn - 1
            
            # For boards with even columns we separate the center by one more column
            self.p1_last_index = max(0, left_index-1)
            self.p2_first_index = min(self.columns-1, right_index+1)

    def get_direction(self, start_coords, destination_coords):
        (s_row, s_col) = start_coords
        (d_row, d_col) = destination_coords
        vector = (d_row - s_row, d_col - s_col)
        
        match vector:
            case (-1, -1):
                return "nw"
            
            case (-1, 0):
                return "n"
            
            case (0, -1):
                if s_col % 2 == 0:
                    return "sw"
                else:
                    return "nw"
                
            case (1, -1):
                return "sw"
            
            case (-1, 1):
                return "ne"
            
            case (0, 1):
                if s_col % 2 == 0:
                    return "se"
                else:
                    return "ne"

            case (1, 0):
                return "s"

            case (1, 1):
                return "se"

            case _:
                raise Exception("get_direction() invalid vector.")

    def get_n_coords(self, coords):
        (row, col) = coords
        n = (row-1, col)
        return n
    
    def get_ne_coords(self, coords):
        (row, col) = coords
        if col % 2 == 0:
            ne = (row-1, col+1)
        else:
            ne = (row, col+1)

        return ne
    
    def get_se_coords(self, coords):
        (row, col) = coords
        if col % 2 == 0:
            se = (row, col+1)
        else:
            se = (row+1, col+1)
    
        return se
    
    def get_s_coords(self, coords):
        (row, col) = coords
        s = (row+1, col)
        return s

    def get_sw_coords(self, coords):
        (row, col) = coords
        if col % 2 == 0:
            sw = (row, col-1)
        else:
            sw = (row+1, col-1)

        return sw
    
    def get_nw_coords(self, coords):
        (row, col) = coords
        if col % 2 == 0:
            nw = (row-1, col-1)
        else:
            nw = (row, col-1)

        return nw

    def get_direction_from_index(self, index):
        directions = ["n", "ne", "se", "s", "sw", "nw"]
        return directions[index]
    
    def get_index_from_direction(self, direction):
        directions = ["n", "ne", "se", "s", "sw", "nw"]
        return directions.index(direction)
    
    def get_strongest_defender(self, units_list):
        # returns the unit from the list which has the highest defense
        # In case of a draw, attack and movement allowance are used to select the unit

        strongest_unit = units_list[0]
        for unit in units_list:
            if unit.defense > strongest_unit.defense:
                strongest_unit = unit
            elif unit.defense == strongest_unit.defense:
                if unit.attack > strongest_unit.attack:
                    strongest_unit = unit
                elif unit.attack == strongest_unit.attack:
                    if unit.mov_allowance > strongest_unit.mov_allowance:
                        strongest_unit = unit

        return strongest_unit
    
    def get_strongest_attacker(self, units_list):
        # returns the unit from the list which has the highest attack
        # In case of a draw, defense and movement allowance are used to select the unit

        strongest_unit = units_list[0]
        for unit in units_list:
            if unit.attack > strongest_unit.attack:
                strongest_unit = unit
            elif unit.attack == strongest_unit.attack:
                if unit.defense > strongest_unit.defense:
                    strongest_unit = unit
                elif unit.defense == strongest_unit.defense:
                    if unit.mov_allowance > strongest_unit.mov_allowance:
                        strongest_unit = unit

        return strongest_unit

    def get_movement_action(self, unit_position, unit_stacking, destination):
        '''Returns the action index for a specific movement action
           If unit_position and destination are the same, the "No_move" action will be assumed
        '''
        #plane order -> placement_planes, movement_planes, choose_target_planes, choose_attackers_planes, confirm_attack_planes, no_move_planes, no_fight_planes
        
        (x,y) = unit_position
        if unit_position != destination:
            direction = self.get_direction(unit_position, destination)
            dir_index = self.get_index_from_direction(direction)
            movement_index = ((dir_index * self.stacking_limit) + unit_stacking)
            plane_index = self.placement_limit + movement_index
            action_coords = (plane_index, x, y)
        else: # no move
            plane_index = self.confirm_limit + unit_stacking
            action_coords = (plane_index, x, y)

        action_i = self.get_action_index(action_coords)
        return action_i, action_coords
    
    def get_target_action(self, target_position):
        '''Returns the action index for a specific targeting action'''
        (x,y) = target_position
        plane_index = self.movement_limit
        action_coords = (plane_index, x, y)
        action_i = self.get_action_index(action_coords)
        return action_i, action_coords
    
    def get_skip_combat_action(self, unit_position, unit_stacking):
        '''Returns the action index for a unit skiping combat'''
        (x,y) = unit_position
        plane_index = self.no_move_limit + unit_stacking
        action_coords = (plane_index, x, y)
        action_i = self.get_action_index(action_coords)
        return action_i, action_coords
    
    def get_confirm_attack_action(self):
        '''Returns the action index for confirming the current attack'''
        (x,y) = self.target_tile.position
        plane_index = self.attackers_limit
        action_coords = (plane_index, x, y)
        action_i = self.get_action_index(action_coords)
        return action_i, action_coords
    
    def get_next_reinforcement(self):
        player = self.current_player
        return self.current_reinforcements[player][self.current_turn][0]

    def get_action_coords(self, action_i: np.integer):
        action_coords = np.unravel_index(action_i, self.get_action_space_shape())
        return action_coords
    
    def get_action_index(self, action_coords):
        action_i = np.ravel_multi_index(action_coords, self.get_action_space_shape())
        return action_i 

    def string_action(self, action_coords):

        parsed_action = self.parse_action(action_coords)
        act = parsed_action[0]
        start = parsed_action[1]
        stacking_lvl = parsed_action[2]
        dest = parsed_action[3]

        string = ""
        if (act == 0): # placement
            string = "Movement phase: Placing reinforcement "
        
            string = string + "at (" + str(start[0]+1) + "," + str(start[1]+1) + ")"

        elif (act == 1): # movement
            string = "Movement phase: Moving from (" + str(start[0]+1) + "," + str(start[1]+1) + ") " + "to (" + str(dest[0]+1) + "," + str(dest[1]+1) + ")"
        
        elif (act == 2): # choose target
            string = "Fighting phase: Targeting the tile at (" + str(start[0]+1) + "," + str(start[1]+1) + ")"

        elif (act == 3): # choose attacker
            string = "Fighting phase: Chose the unit in tile (" + str(start[0]+1) + "," + str(start[1]+1) + ") at stacking level:" + str(stacking_lvl) + ", to join the attack"

        elif (act == 4): # confirm attack
            string = "Fighting phase: Attack to tile (" + str(start[0]+1) + "," + str(start[1]+1) + ") confirmed"

        elif (act == 5): # no move
            string = "Movement phase: Unit at (" + str(start[0]+1) + "," + str(start[1]+1) + ") " + "chose not to move"

        elif (act == 6): # no fight
            string = "Fighting phase: Unit at (" + str(start[0]+1) + "," + str(start[1]+1) + ") " + "chose not to fight"

        else:
            string = "Unknown action..."

        #print(string)
        return string
    
    def print_possible_actions(self):
        possible_actions = self.possible_actions()
        action_indexes = list(zip(*np.nonzero(possible_actions)))

        for action in action_indexes:
            print(self.string_action(action))


##########################################################################
# ----------------------------             ----------------------------- #
# --------------------------    PettingZoo    -------------------------- #
# ----------------------------             ----------------------------- #
##########################################################################
    
    def state(self) -> np.ndarray:
        '''
        PettingZoo expects the state to be a numpy array.
        
        Returns state in format determined by obs_space_format:
        - channels_first: (C, H, W) - PyTorch convention
        - channels_last: (H, W, C) - TensorFlow/RLlib convention
        - flat: (C * H * W,) - 1D flattened
        '''
        state = self.generate_state().numpy()
        if self.obs_space_format == "channels_last":
            # Transpose from (C, H, W) to (H, W, C)
            state = np.transpose(state, (1, 2, 0))
        elif self.obs_space_format == "flat":
            state = state.flatten()
        return state

    def observe(self, agent: str) -> np.ndarray | dict:
        '''
        Since the game is fully observable,
        the entire game state will always be observed by both agents.
        
        Returns observation in format determined by action_mask_location:
        - "info": returns just the state array (action mask is in info dict)
        - "obs": returns dict with "observation" and "action_mask" keys
        '''
        if self.action_mask_location == "obs":
            return {
                "observation": self.state(),
                "action_mask": self.infos[agent]["action_mask"]
            }
        else:  # "info"
            return self.state()
    
    def last(self, observe=True):
        """
        Returns observation, cumulative_reward, terminated, truncated, info for the current agent
        This is required by the PettingZoo AEC API
        """
        agent = self.agent_selection
        observation = self.observe(agent) if observe else None
        return (
            observation,
            self._cumulative_rewards[agent],
            self.terminations[agent],
            self.truncations[agent],
            self.infos[agent]
        )
    
    def render(self, mode: Literal["human", "rbg_array", "ansi"]):
        return self.renderer.render_frame(self, mode=mode)

    def close(self):
        self.renderer.close()
    
##########################################################################
# -------------------------                   -------------------------- #
# ------------------------  ALPHAZERO SUPPORT  ------------------------- #
# -------------------------                   -------------------------- #
##########################################################################

    def generate_state(self):
        ''' Generates a pytorch tensor representing the game state '''
        data_type = torch.float32

        # Terrain Channels #
        atack_modifiers = torch.ones((self.rows, self.columns), dtype=data_type)
        defense_modifiers = torch.ones((self.rows, self.columns), dtype=data_type)
        movement_costs = torch.ones((self.rows, self.columns), dtype=data_type)

        for i in range(self.rows):
            for j in range(self.columns):
                tile = self.board[i][j]
                terrain = tile.get_terrain()
                a = terrain.attack_modifier
                d = terrain.defense_modifier
                m = terrain.cost
                atack_modifiers[i][j] = a
                defense_modifiers[i][j] = d
                movement_costs[i][j] = m

        atack_modifiers = torch.unsqueeze(atack_modifiers, 0)
        defense_modifiers = torch.unsqueeze(defense_modifiers, 0)
        movement_costs = torch.unsqueeze(movement_costs, 0)


        # Reinforcements Channels #
        player_reinforcements = [None, None]
        for player, reinforcements in self.current_reinforcements.items():
            represented_units = 0
            for turn in range(len(reinforcements)):
                turns_left = turn - self.current_turn
                relative_importance = (self.turns + 1) - turns_left
                normalized_importance = relative_importance / (self.turns + 1)

                turn_reinforcements = reinforcements[turn]
                for unit in turn_reinforcements:
                    arraival_locations = unit.get_arraival_locations()
                    attack_plane = torch.zeros((1, self.rows, self.columns), dtype=data_type)
                    defense_plane = torch.zeros((1, self.rows, self.columns), dtype=data_type)
                    movement_plane = torch.zeros((1, self.rows, self.columns), dtype=data_type)
                    for (row, col) in arraival_locations:
                        attack_plane[0][row][col] = unit.attack
                        defense_plane[0][row][col] = unit.defense
                        movement_plane[0][row][col] = unit.mov_points
                    
                    stats_planes = torch.cat((attack_plane, defense_plane, movement_plane))
                    duration_planes = torch.full((self.N_UNIT_STATS, self.rows, self.columns), normalized_importance, dtype=data_type)
                    unit_planes = torch.cat((stats_planes, duration_planes))

                    if player_reinforcements[player] is None:
                        player_reinforcements[player] = unit_planes
                    else:
                        player_reinforcements[player] = torch.cat((player_reinforcements[player], unit_planes))

                    represented_units +=1
                    if represented_units == self.n_reinforcements:
                        break
                if represented_units == self.n_reinforcements:
                        break
                
            # If the loop ends without reaching a "break" it means we need to fill the rest with "empty" units 
            else: # This else belongs to the "for" loop not the "if" statement
                units_remaining = self.n_reinforcements - represented_units
                for empty_unit in range(units_remaining):
                    unit_planes = torch.zeros((self.N_UNIT_STATS * 2, self.rows, self.columns), dtype=data_type)
                    if player_reinforcements[player] is None:
                        player_reinforcements[player] = unit_planes
                    else:
                        player_reinforcements[player] = torch.cat((player_reinforcements[player], unit_planes))


        p1_reinforcements = player_reinforcements[0]
        p2_reinforcements = player_reinforcements[1]

    
        # Victory Points Channels #
        p1_victory = torch.zeros((self.rows, self.columns), dtype=data_type)
        p2_victory = torch.zeros((self.rows, self.columns), dtype=data_type)

        for v in self.victory_points[0]:
            x = v[0]
            y = v[1]
            p1_victory[x][y] = 1.0

        for v in self.victory_points[1]:
            x = v[0]
            y = v[1]
            p2_victory[x][y] = 1.0

        p1_victory = torch.unsqueeze(p1_victory, 0)
        p2_victory = torch.unsqueeze(p2_victory, 0)


        # Unit Representation Channels #
        p1_units = torch.zeros((self.N_UNIT_STATS * self.stacking_limit * self.N_UNIT_STATUSES, self.rows, self.columns), dtype=data_type)
        p2_units = torch.zeros((self.N_UNIT_STATS * self.stacking_limit * self.N_UNIT_STATUSES, self.rows, self.columns), dtype=data_type)
        p_units = [p1_units, p2_units]
        for p in [0,1]: 
            # for each player check each unit status
            statuses_list = [self.available_units[p], self.moved_units[p], self.attacked_units[p]]
            for status_index in range(len(statuses_list)):
                unit_list = statuses_list[status_index]
                # within each status we represent each unit using their stacking level and stats
                for unit in unit_list:
                    (row, col) = unit.position
                    tile = self.board[row][col]
                    s = tile.get_stacking_level(unit)
                    stacking_offset = s * self.N_UNIT_STATS
                    status_offset = status_index * self.stacking_limit * self.N_UNIT_STATS
                    p_units[p][status_offset + stacking_offset + 0][row][col] = unit.attack
                    p_units[p][status_offset + stacking_offset + 1][row][col] = unit.defense
                    p_units[p][status_offset + stacking_offset + 2][row][col] = unit.mov_points
        
        # Target tile channel #
        target_tile_plane = torch.zeros((1, self.rows, self.columns), dtype=data_type)
        if self.target_tile is not None:
            (x, y) = self.target_tile.position
            target_tile_plane[0][x][y] = 1.0

        # Attackers channels #
        attackers = torch.zeros((self.stacking_limit, self.rows, self.columns), dtype=data_type)
        for unit in self.attackers:
            (x, y) = unit.position
            tile = self.board[x][y]
            stacking_lvl = tile.get_stacking_level(unit)
            attackers[stacking_lvl][x][y] = 1.0

        # Sub-Phase Channel #
        sub_phase_index = self.current_sub_phase
        sub_phase_planes = torch.zeros((self.SUB_PHASES, self.rows, self.columns), dtype=data_type)
        active_sub_phase = torch.ones((self.rows, self.columns), dtype=data_type)
        sub_phase_planes[sub_phase_index] = active_sub_phase
        
        # Turn Channel #
        turn_percent = self.current_turn/self.turns
        turn_plane = torch.full((self.rows, self.columns), turn_percent, dtype=data_type)
        turn_plane = torch.unsqueeze(turn_plane, 0)

        # Player Channel #
        player_plane = torch.ones((self.rows,self.columns), dtype=data_type)
        if self.current_player == 1:
            player_plane = torch.full((self.rows,self.columns), fill_value=-1, dtype=data_type)

        player_plane = torch.unsqueeze(player_plane, 0)

        # Final operations #
        stack_list = []

        terrain_list = [atack_modifiers, defense_modifiers, movement_costs]
        stack_list.extend(terrain_list)
    
        core_list = [p1_victory, p2_victory, p1_reinforcements, p2_reinforcements, p1_units, p2_units,
                     target_tile_plane, attackers, sub_phase_planes, turn_plane, player_plane]
        stack_list.extend(core_list)

        game_state = torch.concat(stack_list, dim=0)
        #print(game_image)
        return game_state 
    
    def generate_network_input(self):
        '''
        Generates a pytorch tensor representing the state
        including a batch dimension, so that it can be used
        as input for neural network inference 
        '''
        game_state = self.generate_state()
        state_image = torch.unsqueeze(game_state, 0) # add batch size to the dimensions
        return state_image

    def store_search_statistics(self, node):
        sum_visits = sum(child.visit_count for child in node.children.values())
        self.child_policy.append(
            [ node.children[a].visit_count / sum_visits if a in node.children else 0
            for a in range(self.num_actions) ])

    def make_target(self, i):
        value_target = self.terminal_value
        policy_target = self.child_policy[i]

        target = (value_target, policy_target)
        return target
        

    # --------  DEBUG  -------- #

    def set_simple_game_state(self, turn, unit_ids_list, unit_position_list, player_list):
        self.lenght = 0 # artificial game states don't have previous actions

        if len(unit_ids_list) != len(unit_position_list) or len(unit_ids_list) != len(player_list):
            raise Exception("set_simple_game_state()\nAll lists must have the same length.")

        # Create the units and place them at the specified position
        for i in range(len(unit_ids_list)):
            unit_id = unit_ids_list[i]
            position = unit_position_list[i]
            player = player_list[i] - 1
            player_index = player

            unit_details = self.units_by_id[unit_id]
            new_unit = self.create_unit(unit_details, player)

            new_unit.move_to(position, 0)
            self.available_units[player_index].append(new_unit)
            tile = self.get_tile(position)
            tile.place_unit(new_unit)

        # Clear the reinforcements for the previous turns
        for reinforcements in self.current_reinforcements.values():
            for t in range(turn+1):
                reinforcements[t].clear()
            
        # Set the turn and make sure the environment is updated
        self.current_turn = turn
        self.current_stage = 0
        self.update_game_env()
        return

    def debug_state_image(self, state_image):
        print("\n")
        print("---------" + ("----" * self.columns))
        print("\n")

        state = state_image[0]

        section_names = ["TERRAIN", "VICTORY POINTS", "P1_REINFORCEMENTS", "P2_REINFORCEMENTS",
                         "P1_UNITS", "P2_UNITS", "TARGET TILE", "ATTACKERS", "SUBPHASES", "TURN", "PLAYER"]
        section_sizes = [self.n_terrain_channels, self.n_vp_channels, self.n_total_reinforcement_channels//2, self.n_total_reinforcement_channels//2, 
                         self.n_unit_representation_channels//2, self.n_unit_representation_channels//2, self.n_target_tile_channels,
                         self.n_attacker_channels, self.n_sub_phase_channels, 1, 1]

        limit = 0
        section_index = 0
        for channel_idx in range(len(state)):
            channel = state[channel_idx]
            
            if channel_idx == limit:
                print("\n" + section_names[section_index])
                size = section_sizes[section_index]
                if torch.count_nonzero(state[limit:limit+size]) == 0:
                    print("\n(empty)\n")
                    empty_section = True
                else:
                    empty_section = False

                limit += size
                section_index += 1

            if not empty_section:
                print(channel)
            

##########################################################################
# -------------------------                    ------------------------- #
# ------------------------   INSTANCE METHODS   ------------------------ #
# -------------------------                    ------------------------- #
##########################################################################

    def load_game_from_config(self, filename, seed):
        # Load config into dictionary
        with open(filename, 'r') as stream:
            data_loaded = yaml.safe_load(stream)
        
        if seed:
            np.random.seed(seed)

        self.units_by_id = {}
        self.terrain_by_id = {}
        
        # Parse the dictionary information
        for section_name, values in data_loaded.items():
            match section_name:
                case "Name":
                    self.title = values
                    
                case "Board_dimensions":
                    self.rows = values["rows"]
                    self.columns = values["columns"]
                    self.define_board_sides()

                case "Turns":
                    self.turns = values

                case "Stacking_limit":
                    self.stacking_limit = values

                case "Units":
                    for unit_name, properties in values.items():
                        id = properties["id"]
                        properties.pop("id")
                        self.units_by_id[id] = {}
                        self.units_by_id[id]["name"] = unit_name
                        self.units_by_id[id].update(properties)
         
                case "Reinforcements":
                    schedule = values["schedule"]
                    arrival = values["arrival"]
                    arrival_method = arrival["method"]

                    if arrival_method == "Default":
                        player_arrival_locations = [[], []]
                        for i in range(self.rows):
                            for j in range(self.columns):
                                location = (i,j)
                                if j <= self.p1_last_index:
                                    player_arrival_locations[0].append(location)
                                elif j >= self.p2_first_index:
                                    player_arrival_locations[1].append(location)
                    elif arrival_method == "Detailed":
                        locations = [[],[]]
                        p_locations = arrival["locations"]
                        locations[0] = p_locations["p1"]
                        locations[1] = p_locations["p2"]
                        unit_indexes = [0, 0]

                    for p, reinforcement_schedule in schedule.items():
                        num_turns = len(reinforcement_schedule)
                        if num_turns != (self.turns + 1):
                            raise Exception("\nError in config.\n" +
                                  "Reinforcement schedule should have \'turns + 1\' entries.\n" +
                                  "In order to account for initial troop placement (turn 0).")
    
                        player = int(p[-1]) - 1
                        player_index = player
                        self.all_reinforcements[player_index] = []
                        self.current_reinforcements[player_index] = []
                        for turn_idx in range(num_turns):
                            turn_units = reinforcement_schedule[turn_idx]

                            self.all_reinforcements[player_index].append([])
                            self.current_reinforcements[player_index].append([])
                            for id in turn_units:
                                unit_details = self.units_by_id[id]
                                new_unit = self.create_unit(unit_details, player)
                                
                                if arrival_method == "Default":
                                    unit_arrival_locations = player_arrival_locations[player_index]
                                elif arrival_method == "Detailed":
                                    unit_arrival_locations = [ tuple(point) for point in locations[player_index][unit_indexes[player_index]] ]
                                    unit_indexes[player_index]+=1

                                new_unit.set_arraival_locations(unit_arrival_locations)
                                self.current_reinforcements[player_index][turn_idx].append(new_unit)

                    self.all_reinforcements = deepcopy(self.current_reinforcements)

                case "Terrain":
                    for terrain_name, properties in values.items():
                        id = properties["id"]
                        properties.pop("id")
                        self.terrain_by_id[id] = {}
                        self.terrain_by_id[id]["name"] = terrain_name
                        self.terrain_by_id[id].update(properties)

                case "Map":
                    self.terrain_types = []
                    for id, properties in self.terrain_by_id.items():
                        instance =  Terrain(
                            attack_modifier=properties["attack_modifier"],
                            defense_modifier=properties["defense_modifier"],
                            cost=properties["cost"], 
                            name=properties["name"],
                            image_path=properties["image_path"])
                        
                        properties["instance"] = instance
                        self.terrain_types.append(instance)

                    method = values["creation_method"]
                    if method == "Randomized":
                        if values.get("distribution"):
                            distribution = values["distribution"]
                        else:
                            num_terrains = len(self.terrain_by_id)
                            distribution = [1/num_terrains for _ in range(num_terrains)]

                        for i in range(self.rows):
                            self.board.append([])
                            for j in range(self.columns):
                                terrain = np.random.choice(self.terrain_types, p=distribution)
                                self.board[i].append(Tile((i,j), terrain))

                    elif method == "Detailed":
                        map_configuration = values["map_configuration"]
                        map_shape = np.shape(map_configuration)
                        if map_shape != (self.rows, self.columns):
                            raise Exception("Wrong shape for map configuration, when loading game config.")
                        else:
                            for i in range(self.rows):
                                self.board.append([])
                                for j in range(self.columns):
                                    terrain_id = map_configuration[i][j]
                                    terrain = self.terrain_by_id[terrain_id]["instance"]
                                    self.board[i].append(Tile((i,j), terrain))
                    else:
                        raise Exception("Unrecognized map creation method, when loading game config.")

                case "Victory_points":
                    method = values["creation_method"]

                    if method == "Randomized":
                        p1_vp = values["number_vp"]["p1"]
                        p2_vp = values["number_vp"]["p2"]
                        self.victory_points = [[],[]]        

                        p1_available_tiles = self.rows * (self.p1_last_index+1)
                        p2_available_tiles = self.rows * ((self.columns - (self.p2_first_index+1)) + 1)
                        if p1_vp > p1_available_tiles:
                            raise Exception("Game config has too many victory points for p1.")
                        
                        if p2_vp > p2_available_tiles:
                            raise Exception("Game config has too many victory points for p2.")

                        for _ in range(p1_vp):
                            row = np.random.choice(range(self.rows))
                            col = np.random.choice(range(self.p1_last_index+1))
                            point = (row, col)
                            while point in self.victory_points[0]:
                                row = np.random.choice(range(self.rows))
                                col = np.random.choice(range(self.p1_last_index+1))
                                point = (row, col)

                            self.victory_points[0].append(point)
                        
                        for _ in range(p2_vp):
                            row = np.random.choice(range(self.rows))
                            col = np.random.choice(range(self.p2_first_index, self.columns))
                            point = (row, col)
                            while point in self.victory_points[1]:
                                row = np.random.choice(range(self.rows))
                                col = np.random.choice(range(self.p2_first_index, self.columns))
                                point = (row, col)

                            self.victory_points[1].append(point)


                    elif method == "Detailed":
                        p1_vp = values["vp_locations"]["p1"]
                        p2_vp = values["vp_locations"]["p2"]
                        self.victory_points = [[],[]]        

                        loaded_vps = [p1_vp, p2_vp]
                        for player in range(len(loaded_vps)):
                            loaded_list = loaded_vps[player]
                            game_list = self.victory_points[player]
                            for point in loaded_list:
                                if len(point) != 2:
                                    raise Exception(str(point) + " --> Points must have two coordenates. (game config)")
                                    
                                elif point in game_list:
                                    raise Exception(str(point) + " --> Repeated point. Cannot have two points with the same coordenates. (game config)")
                                    
                                else:
                                    vp_tuple = (point[0], point[1])
                                    game_list.append(vp_tuple)        

                    else:
                        raise Exception("Unrecognized victory points creation method. (game config)")

                    self.n_vp = [0, 0]
                    for point in self.victory_points[0]:
                        self.board[point[0]][point[1]].victory = 1
                        self.n_vp[0] += 1

                    for point in self.victory_points[1]:
                        self.board[point[0]][point[1]].victory = 2
                        self.n_vp[1] += 1

    def clone(self):
        return deepcopy(self)
    
    def shallow_clone(self):
        ignore_list = ["child_policy", "state_history", "player_history", "action_history"]
        new_game = SCS_Game()

        memo = {} # memo dict for deepcopy so that it knows what objects it has already copied before
        attributes = self.__dict__.items()
        for name, value in attributes:
            if (not(name.startswith('__') and name.endswith('__'))) and (name not in ignore_list):
                value_copy = deepcopy(value, memo)
                setattr(new_game, name, value_copy)
                
        return new_game

    def create_unit(self, unit_details, player):
        name = unit_details["name"]
        attack = unit_details["attack"]
        defense = unit_details["defense"]
        mov_allowance = unit_details["movement"]
        image_path = unit_details.get("image_path")
        if image_path is None:
            image_name = "p" + str(player) + "_" + name
            image_path = str(self.package_root / "assets" / f"{image_name}.jpg")
            if not os.path.isfile(image_path):
                print("No image path provided")
                print("Automatically creating image for unit.")
                print("Image locaton: " + image_path + "\n\n")

                stats=(attack, defense, mov_allowance)
                if player == 0:
                    color_str = "dark_green"
                    border_color = "green"
                elif player == 1:
                    color_str = "dark_red"
                    border_color = "red"
                else:
                    raise Exception("Found Unknown player when creating unit.")
                    
                source_path = self.renderer.counter_creator.create_counter_from_scratch(
                    image_name,
                    stats,
                    "infantary",
                    color_str=color_str
                )
                image_path = self.renderer.counter_creator.add_border(border_color, source_path)

        else:
            # If image_path is provided but relative, make it absolute relative to package root
            if not os.path.isabs(image_path):
                image_path = str(self.package_root / "assets" / image_path)
            
            if not os.path.isfile(image_path):
                raise Exception(str(image_path) + " --> Image path provided to create unit, does not point to any file.")


        new_unit = Unit(name, attack, defense, mov_allowance, player, [], image_path)
        return new_unit



